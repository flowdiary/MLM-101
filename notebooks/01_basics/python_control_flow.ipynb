{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e049f29",
   "metadata": {},
   "source": [
    "# Python Control Flow and Loops\n",
    "\n",
    "**Course:** MLM-101 - Machine Learning Mastery  \n",
    "**Phase 2:** Python Programming (Lectures 11-12)  \n",
    "**Topics:** For Loops, While Loops, Loop Control, Iterations\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "‚úÖ Use `for` loops to iterate over sequences  \n",
    "‚úÖ Use `while` loops for conditional iteration  \n",
    "‚úÖ Control loop execution with `break` and `continue`  \n",
    "‚úÖ Use `range()` function effectively  \n",
    "‚úÖ Apply loops to ML preprocessing tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ddbef",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ For Loops\n",
    "\n",
    "Iterate over a sequence (list, string, range, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703174ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic for loop\n",
    "algorithms = [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Neural Network\"]\n",
    "\n",
    "print(\"Machine Learning Algorithms:\")\n",
    "for algorithm in algorithms:\n",
    "    print(f\"  - {algorithm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop with index using enumerate()\n",
    "models = [\"Model A\", \"Model B\", \"Model C\"]\n",
    "accuracies = [0.92, 0.89, 0.95]\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "for index, (model, accuracy) in enumerate(zip(models, accuracies), start=1):\n",
    "    print(f\"{index}. {model}: {accuracy * 100}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9d6c8",
   "metadata": {},
   "source": [
    "### üí° Using range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bdede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(stop) - from 0 to stop-1\n",
    "print(\"Training for 5 epochs:\")\n",
    "for epoch in range(5):\n",
    "    print(f\"  Epoch {epoch + 1}/5\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# range(start, stop) - from start to stop-1\n",
    "print(\"Processing batches 10-14:\")\n",
    "for batch in range(10, 15):\n",
    "    print(f\"  Processing batch {batch}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# range(start, stop, step)\n",
    "print(\"Learning rate decay (every 5 epochs):\")\n",
    "for epoch in range(0, 21, 5):\n",
    "    lr = 0.1 / (1 + epoch * 0.01)\n",
    "    print(f\"  Epoch {epoch}: LR = {lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847bcb5",
   "metadata": {},
   "source": [
    "### üéØ ML Example: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a training loop\n",
    "num_epochs = 5\n",
    "initial_loss = 2.5\n",
    "\n",
    "print(\"Training Neural Network...\\n\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Simulate decreasing loss\n",
    "    loss = initial_loss / epoch\n",
    "    accuracy = min(0.95, 0.60 + (epoch * 0.08))\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    print(f\"  Loss: {loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f766ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ While Loops\n",
    "\n",
    "Repeat while a condition is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec627c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic while loop\n",
    "epoch = 1\n",
    "target_accuracy = 0.90\n",
    "current_accuracy = 0.70\n",
    "\n",
    "print(\"Training until target accuracy...\\n\")\n",
    "while current_accuracy < target_accuracy:\n",
    "    print(f\"Epoch {epoch}: Accuracy = {current_accuracy:.2%}\")\n",
    "    \n",
    "    # Simulate improvement\n",
    "    current_accuracy += 0.05\n",
    "    epoch += 1\n",
    "    \n",
    "    # Safety: prevent infinite loop\n",
    "    if epoch > 10:\n",
    "        print(\"\\nMax epochs reached!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ Target achieved! Final accuracy: {current_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8427e8",
   "metadata": {},
   "source": [
    "### üí° While with User Input Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent simulation\n",
    "learning_rate = 0.1\n",
    "current_loss = 10.0\n",
    "threshold = 0.5\n",
    "iteration = 0\n",
    "\n",
    "print(\"Gradient Descent Optimization\\n\")\n",
    "while current_loss > threshold and iteration < 20:\n",
    "    iteration += 1\n",
    "    # Simulate loss decrease\n",
    "    gradient = current_loss * 0.3\n",
    "    current_loss -= learning_rate * gradient\n",
    "    \n",
    "    print(f\"Iteration {iteration}: Loss = {current_loss:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Converged after {iteration} iterations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f39d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Loop Control: break and continue\n",
    "\n",
    "Control loop execution flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62943f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break: Exit loop early\n",
    "print(\"Early Stopping Example:\\n\")\n",
    "\n",
    "epochs = 10\n",
    "patience = 3\n",
    "best_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "losses = [2.5, 2.1, 1.9, 1.85, 1.84, 1.83, 1.83, 1.82, 1.82, 1.81]\n",
    "\n",
    "for epoch, loss in enumerate(losses, start=1):\n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.2f}\")\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        no_improvement_count = 0\n",
    "        print(\"  ‚Üí New best loss!\")\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        print(f\"  ‚Üí No improvement ({no_improvement_count}/{patience})\")\n",
    "    \n",
    "    if no_improvement_count >= patience:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest Loss: {best_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue: Skip to next iteration\n",
    "print(\"Processing samples (skipping corrupted):\")\n",
    "\n",
    "sample_ids = [101, 102, 103, 104, 105, 106, 107, 108]\n",
    "corrupted_ids = [103, 106]  # Corrupted samples\n",
    "\n",
    "processed_count = 0\n",
    "for sample_id in sample_ids:\n",
    "    # Skip corrupted samples\n",
    "    if sample_id in corrupted_ids:\n",
    "        print(f\"  ‚ö†Ô∏è Sample {sample_id}: SKIPPED (corrupted)\")\n",
    "        continue\n",
    "    \n",
    "    # Process valid samples\n",
    "    processed_count += 1\n",
    "    print(f\"  ‚úÖ Sample {sample_id}: Processed\")\n",
    "\n",
    "print(f\"\\nTotal processed: {processed_count}/{len(sample_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766aa526",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Nested Loops\n",
    "\n",
    "Loops inside loops - common in ML for processing batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Example: Training with batches\n",
    "num_epochs = 3\n",
    "num_batches = 4\n",
    "\n",
    "print(\"Training with Mini-Batches\\n\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in range(1, num_batches + 1):\n",
    "        # Simulate batch loss\n",
    "        batch_loss = 2.0 / (epoch * batch)\n",
    "        epoch_loss += batch_loss\n",
    "        print(f\"  Batch {batch}/{num_batches}: Loss = {batch_loss:.4f}\")\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    print(f\"  ‚Üí Average Loss: {avg_loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid Search\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "print(\"Grid Search Results:\\n\")\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        # Simulate training (random accuracy)\n",
    "        import random\n",
    "        random.seed(int(lr * 1000 + batch_size))\n",
    "        accuracy = random.uniform(0.80, 0.95)\n",
    "        \n",
    "        print(f\"LR={lr}, Batch={batch_size} ‚Üí Accuracy={accuracy:.2%}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
    "\n",
    "print(f\"\\nüèÜ Best: LR={best_params['lr']}, Batch={best_params['batch_size']}\")\n",
    "print(f\"   Accuracy: {best_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d168b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ List Comprehensions\n",
    "\n",
    "Concise way to create lists using loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional loop\n",
    "squares = []\n",
    "for i in range(1, 6):\n",
    "    squares.append(i ** 2)\n",
    "print(f\"Traditional: {squares}\")\n",
    "\n",
    "# List comprehension (same result, more concise)\n",
    "squares = [i ** 2 for i in range(1, 6)]\n",
    "print(f\"Comprehension: {squares}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Example: Normalize predictions\n",
    "raw_predictions = [2.5, 3.8, 1.2, 4.5, 2.9]\n",
    "\n",
    "# Min-max normalization to [0, 1]\n",
    "min_val = min(raw_predictions)\n",
    "max_val = max(raw_predictions)\n",
    "\n",
    "normalized = [(x - min_val) / (max_val - min_val) for x in raw_predictions]\n",
    "\n",
    "print(\"Original:\", raw_predictions)\n",
    "print(\"Normalized:\", [f\"{x:.2f}\" for x in normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76925b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension with condition\n",
    "accuracies = [0.92, 0.78, 0.95, 0.81, 0.88, 0.73]\n",
    "\n",
    "# Filter models with accuracy >= 0.85\n",
    "good_models = [acc for acc in accuracies if acc >= 0.85]\n",
    "\n",
    "print(f\"All accuracies: {accuracies}\")\n",
    "print(f\"Good models (‚â•85%): {good_models}\")\n",
    "print(f\"Count: {len(good_models)}/{len(accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58c1eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Practice Exercises\n",
    "\n",
    "### Exercise 1: Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 100 samples in batches of 16\n",
    "# Print: \"Processing batch X: samples Y-Z\"\n",
    "\n",
    "total_samples = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Your code here:\n",
    "for batch_num in range((total_samples + batch_size - 1) // batch_size):\n",
    "    start = batch_num * batch_size\n",
    "    end = min(start + batch_size, total_samples)\n",
    "    print(f\"Processing batch {batch_num + 1}: samples {start}-{end-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38c428",
   "metadata": {},
   "source": [
    "### Exercise 2: Convergence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019dff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep training while loss > 0.01 OR epochs < 100\n",
    "# Loss decreases by 10% each epoch\n",
    "\n",
    "loss = 5.0\n",
    "epoch = 0\n",
    "max_epochs = 100\n",
    "target_loss = 0.01\n",
    "\n",
    "# Your code here:\n",
    "while loss > target_loss and epoch < max_epochs:\n",
    "    epoch += 1\n",
    "    loss *= 0.9  # 10% reduction\n",
    "    if epoch % 10 == 0:  # Print every 10 epochs\n",
    "        print(f\"Epoch {epoch}: Loss = {loss:.6f}\")\n",
    "\n",
    "print(f\"\\nFinal: Epoch {epoch}, Loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c921ab7",
   "metadata": {},
   "source": [
    "### Exercise 3: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16404f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 3 augmentations to 5 images\n",
    "# Augmentations: flip, rotate, crop\n",
    "\n",
    "images = [\"img1.jpg\", \"img2.jpg\", \"img3.jpg\", \"img4.jpg\", \"img5.jpg\"]\n",
    "augmentations = [\"flip\", \"rotate\", \"crop\"]\n",
    "\n",
    "# Your code here:\n",
    "augmented_images = []\n",
    "for img in images:\n",
    "    for aug in augmentations:\n",
    "        augmented_name = f\"{img.split('.')[0]}_{aug}.jpg\"\n",
    "        augmented_images.append(augmented_name)\n",
    "        print(f\"Created: {augmented_name}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(images)} original ‚Üí {len(augmented_images)} augmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9642c74",
   "metadata": {},
   "source": [
    "### Exercise 4: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features to [0, 1] using list comprehension\n",
    "features = [25, 30, 45, 50, 55, 60, 75]\n",
    "\n",
    "# Your code here:\n",
    "min_f = min(features)\n",
    "max_f = max(features)\n",
    "scaled = [(f - min_f) / (max_f - min_f) for f in features]\n",
    "\n",
    "print(\"Original:\", features)\n",
    "print(\"Scaled:\", [f\"{x:.2f}\" for x in scaled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393400e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "‚úÖ **For Loops**: Iterate over sequences and ranges  \n",
    "‚úÖ **While Loops**: Repeat while condition is True  \n",
    "‚úÖ **Loop Control**: `break` (exit) and `continue` (skip)  \n",
    "‚úÖ **Nested Loops**: Loops within loops for batch processing  \n",
    "‚úÖ **List Comprehensions**: Concise list creation  \n",
    "‚úÖ **ML Applications**: Training loops, batch processing, grid search\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "Continue to:\n",
    "- **`python_data_structures.ipynb`** - Lists, tuples, sets, dictionaries\n",
    "- **`python_functions_oop.ipynb`** - Functions and classes\n",
    "\n",
    "---\n",
    "\n",
    "**Course:** MLM-101 - Machine Learning Mastery  \n",
    "**Website:** [https://flowdiary.com.ng/course/MLM-101](https://flowdiary.com.ng/course/MLM-101)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
