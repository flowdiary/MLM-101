{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450ef101",
   "metadata": {},
   "source": [
    "# Lecture 83 – Hands-On Lab: End-to-End Model Deployment\n",
    "\n",
    "## Lab Objectives\n",
    "In this lab, you will:\n",
    "1. Train a CNN model on Fashion-MNIST\n",
    "2. Serialize the model and artifacts\n",
    "3. Deploy via FastAPI\n",
    "4. Test the API locally\n",
    "5. Containerize with Docker\n",
    "6. (Optional) Deploy to cloud platform\n",
    "\n",
    "## Expected Time\n",
    "~15-20 minutes\n",
    "\n",
    "## Grading Rubric (100 points)\n",
    "- Model Training & Serialization (20 pts)\n",
    "- API Implementation (30 pts)\n",
    "- Testing & Documentation (20 pts)\n",
    "- Docker Containerization (20 pts)\n",
    "- Code Quality & Best Practices (10 pts)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812adebe",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"Deployment timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b65a2",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data\n",
    "\n",
    "**Task**: Load Fashion-MNIST and create train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Use subset for faster training\n",
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 2000\n",
    "\n",
    "x_train = x_train[:TRAIN_SIZE]\n",
    "y_train = y_train[:TRAIN_SIZE]\n",
    "x_test = x_test[:TEST_SIZE]\n",
    "y_test = y_test[:TEST_SIZE]\n",
    "\n",
    "# Normalize\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")\n",
    "print(f\"Input shape: {x_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8ada0",
   "metadata": {},
   "source": [
    "## Step 3: Build and Train Model\n",
    "\n",
    "**Task**: Create a CNN architecture and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49717401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        # TODO: Add your CNN layers here\n",
    "        # Hint: Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0daa783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,  # Increase for better accuracy\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f3d74",
   "metadata": {},
   "source": [
    "## Step 4: Serialize Model\n",
    "\n",
    "**Task**: Save model in multiple formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as HDF5\n",
    "h5_path = models_dir / f\"fashion_cnn_lab_{timestamp}.h5\"\n",
    "model.save(h5_path)\n",
    "print(f\"✓ Saved HDF5: {h5_path.name}\")\n",
    "\n",
    "# Save as SavedModel\n",
    "savedmodel_path = models_dir / f\"fashion_cnn_lab_savedmodel_{timestamp}\"\n",
    "model.save(savedmodel_path, save_format='tf')\n",
    "print(f\"✓ Saved SavedModel: {savedmodel_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing config\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "config = {\n",
    "    'normalization': 'divide_by_255',\n",
    "    'input_shape': [28, 28, 1],\n",
    "    'num_classes': 10,\n",
    "    'class_names': class_names\n",
    "}\n",
    "\n",
    "config_path = models_dir / f\"preprocessing_config_{timestamp}.pkl\"\n",
    "joblib.dump(config, config_path)\n",
    "print(f\"✓ Saved config: {config_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': 'fashion_cnn_lab',\n",
    "    'version': timestamp,\n",
    "    'framework': 'tensorflow',\n",
    "    'framework_version': tf.__version__,\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'training_samples': TRAIN_SIZE,\n",
    "    'epochs': 3,\n",
    "    'created_at': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_path = models_dir / f\"model_metadata_{timestamp}.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved metadata: {metadata_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66287870",
   "metadata": {},
   "source": [
    "## Step 5: Test Model Loading\n",
    "\n",
    "**Task**: Verify saved model works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = tf.keras.models.load_model(savedmodel_path)\n",
    "loaded_config = joblib.load(config_path)\n",
    "\n",
    "print(\"✓ Model and config loaded successfully\")\n",
    "\n",
    "# Test prediction\n",
    "test_image = x_test[0:1]\n",
    "prediction = loaded_model.predict(test_image, verbose=0)\n",
    "predicted_class = prediction.argmax()\n",
    "\n",
    "print(f\"\\nSample Prediction:\")\n",
    "print(f\"  Predicted: {loaded_config['class_names'][predicted_class]}\")\n",
    "print(f\"  Actual: {loaded_config['class_names'][y_test[0]]}\")\n",
    "print(f\"  Confidence: {prediction[0][predicted_class]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732766a",
   "metadata": {},
   "source": [
    "## Step 6: Start FastAPI Server\n",
    "\n",
    "**Task**: Launch the API server\n",
    "\n",
    "In a terminal, run:\n",
    "```bash\n",
    "cd ../apps/fastapi_app\n",
    "uvicorn app:app --host 0.0.0.0 --port 8000 --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if server is running\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def check_server(url=\"http://localhost:8000\", retries=3):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(f\"{url}/ping\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✓ Server is running at {url}\")\n",
    "                return True\n",
    "        except:\n",
    "            if i < retries - 1:\n",
    "                print(f\"Waiting for server... (attempt {i+1}/{retries})\")\n",
    "                time.sleep(2)\n",
    "    \n",
    "    print(\"✗ Server not running\")\n",
    "    print(\"\\nStart server with:\")\n",
    "    print(\"  cd ../apps/fastapi_app\")\n",
    "    print(\"  uvicorn app:app --reload\")\n",
    "    return False\n",
    "\n",
    "server_running = check_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b13bbe",
   "metadata": {},
   "source": [
    "## Step 7: Test API Endpoints\n",
    "\n",
    "**Task**: Verify all endpoints work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0830fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "if server_running:\n",
    "    # Test 1: Health check\n",
    "    print(\"Test 1: Health Check\")\n",
    "    response = requests.get(f\"{API_URL}/ping\")\n",
    "    print(f\"  Status: {response.status_code}\")\n",
    "    print(f\"  Response: {response.json()}\\n\")\n",
    "    \n",
    "    # Test 2: Metadata\n",
    "    print(\"Test 2: Metadata\")\n",
    "    response = requests.get(f\"{API_URL}/metadata\")\n",
    "    print(f\"  Status: {response.status_code}\")\n",
    "    print(f\"  Model: {response.json()['model_name']}\\n\")\n",
    "    \n",
    "    # Test 3: Prediction\n",
    "    print(\"Test 3: Prediction\")\n",
    "    # Get raw test image\n",
    "    (_, _), (x_test_raw, y_test_raw) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    test_images = x_test_raw[:3].tolist()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict\",\n",
    "        json={\"instances\": test_images}\n",
    "    )\n",
    "    \n",
    "    print(f\"  Status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for i, pred in enumerate(results['predictions']):\n",
    "            print(f\"  Image {i+1}: {pred['class_name']} ({pred['confidence']:.4f})\")\n",
    "    \n",
    "    print(\"\\n✓ All API tests passed!\")\n",
    "else:\n",
    "    print(\"Server not running. Skipping API tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87df514",
   "metadata": {},
   "source": [
    "## Step 8: Performance Benchmarking\n",
    "\n",
    "**Task**: Measure API latency and throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77895837",
   "metadata": {},
   "outputs": [],
   "source": [
    "if server_running:\n",
    "    # Benchmark API\n",
    "    import time\n",
    "    \n",
    "    latencies = []\n",
    "    num_requests = 50\n",
    "    \n",
    "    print(f\"Running {num_requests} requests...\")\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        test_image = x_test_raw[i:i+1].tolist()\n",
    "        \n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/predict\",\n",
    "            json={\"instances\": test_image}\n",
    "        )\n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            latencies.append(latency)\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Performance Metrics:\")\n",
    "    print(f\"  Requests: {len(latencies)}\")\n",
    "    print(f\"  Mean latency: {np.mean(latencies):.2f} ms\")\n",
    "    print(f\"  Median latency: {np.median(latencies):.2f} ms\")\n",
    "    print(f\"  P95 latency: {np.percentile(latencies, 95):.2f} ms\")\n",
    "    print(f\"  P99 latency: {np.percentile(latencies, 99):.2f} ms\")\n",
    "    print(f\"  Throughput: {1000 / np.mean(latencies):.2f} req/sec\")\n",
    "    print(f\"{'='*50}\")\n",
    "else:\n",
    "    print(\"Server not running. Skipping benchmark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325333d",
   "metadata": {},
   "source": [
    "## Step 9: Docker Containerization\n",
    "\n",
    "**Task**: Build and test Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Docker image\n",
    "print(\"Building Docker image...\")\n",
    "print(\"\\nRun these commands in terminal:\")\n",
    "print()\n",
    "print(\"cd ../apps/fastapi_app\")\n",
    "print(\"docker build -t fashion-cnn-api:v1.0 .\")\n",
    "print()\n",
    "print(\"# Run container\")\n",
    "print(\"docker run -d \\\\\")\n",
    "print(\"  --name fashion-api \\\\\")\n",
    "print(\"  -p 8000:8000 \\\\\")\n",
    "print(\"  -v $(pwd)/../../models:/app/models \\\\\")\n",
    "print(\"  fashion-cnn-api:v1.0\")\n",
    "print()\n",
    "print(\"# Check logs\")\n",
    "print(\"docker logs -f fashion-api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124177",
   "metadata": {},
   "source": [
    "## Step 10: Documentation\n",
    "\n",
    "**Task**: Create deployment documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_doc = f\"\"\"\n",
    "# Fashion-MNIST CNN Deployment\n",
    "\n",
    "## Model Information\n",
    "- **Model**: Fashion-MNIST CNN Classifier\n",
    "- **Version**: {timestamp}\n",
    "- **Accuracy**: {test_acc:.4f}\n",
    "- **Framework**: TensorFlow {tf.__version__}\n",
    "\n",
    "## Files\n",
    "- Model (H5): {h5_path.name}\n",
    "- Model (SavedModel): {savedmodel_path.name}\n",
    "- Config: {config_path.name}\n",
    "- Metadata: {metadata_path.name}\n",
    "\n",
    "## API Endpoints\n",
    "- `GET /ping` - Health check\n",
    "- `GET /metadata` - Model information\n",
    "- `POST /predict` - Make predictions\n",
    "- `GET /docs` - Interactive documentation\n",
    "\n",
    "## Deployment Steps\n",
    "\n",
    "### Local Deployment\n",
    "```bash\n",
    "# Start server\n",
    "cd apps/fastapi_app\n",
    "uvicorn app:app --host 0.0.0.0 --port 8000\n",
    "```\n",
    "\n",
    "### Docker Deployment\n",
    "```bash\n",
    "# Build\n",
    "docker build -t fashion-cnn-api .\n",
    "\n",
    "# Run\n",
    "docker run -d -p 8000:8000 fashion-cnn-api\n",
    "```\n",
    "\n",
    "### Cloud Deployment\n",
    "See README.md for AWS, GCP, and Azure instructions.\n",
    "\n",
    "## Testing\n",
    "```bash\n",
    "# Health check\n",
    "curl http://localhost:8000/ping\n",
    "\n",
    "# Make prediction\n",
    "curl -X POST http://localhost:8000/predict \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"instances\": [[[0, 0, ...]]]\n",
    "  }}'\n",
    "```\n",
    "\n",
    "## Performance\n",
    "- Mean Latency: {np.mean(latencies):.2f}ms (measured locally)\n",
    "- Throughput: {1000 / np.mean(latencies):.2f} req/sec\n",
    "\n",
    "## Monitoring\n",
    "- Metrics endpoint: `/metrics`\n",
    "- Logs: Check Docker logs or application logs\n",
    "\n",
    "## Maintenance\n",
    "- Model retraining: Run `scripts/01_model_serialization.py`\n",
    "- Update deployment: Rebuild Docker image with new model\n",
    "\"\"\"\n",
    "\n",
    "# Save documentation\n",
    "doc_path = models_dir / f\"DEPLOYMENT_{timestamp}.md\"\n",
    "with open(doc_path, 'w') as f:\n",
    "    f.write(deployment_doc)\n",
    "\n",
    "print(f\"✓ Documentation saved: {doc_path.name}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(deployment_doc[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfe9d4",
   "metadata": {},
   "source": [
    "## Lab Checklist\n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "### Required (90 points)\n",
    "- [ ] Train CNN model with >70% accuracy (20 pts)\n",
    "- [ ] Save model in both H5 and SavedModel formats (10 pts)\n",
    "- [ ] Create preprocessing config and metadata (10 pts)\n",
    "- [ ] Start FastAPI server successfully (15 pts)\n",
    "- [ ] All API endpoints working (15 pts)\n",
    "- [ ] Performance benchmark completed (10 pts)\n",
    "- [ ] Create deployment documentation (10 pts)\n",
    "\n",
    "### Bonus (10 points)\n",
    "- [ ] Docker container built and running (5 pts)\n",
    "- [ ] Deploy to cloud platform (5 pts)\n",
    "\n",
    "## Submission\n",
    "\n",
    "Submit the following:\n",
    "1. This completed notebook\n",
    "2. Model files (H5, SavedModel, config, metadata)\n",
    "3. Deployment documentation\n",
    "4. Screenshot of API docs page (`/docs`)\n",
    "5. (Optional) Docker image or cloud deployment URL\n",
    "\n",
    "---\n",
    "\n",
    "## Extension Ideas\n",
    "\n",
    "1. **A/B Testing**: Deploy two model versions and compare\n",
    "2. **Monitoring Dashboard**: Create Grafana dashboard for metrics\n",
    "3. **CI/CD Pipeline**: Automate deployment with GitHub Actions\n",
    "4. **Load Testing**: Use Locust or k6 for stress testing\n",
    "5. **Model Optimization**: Quantize model to TFLite\n",
    "6. **Multi-model Serving**: Serve multiple models in one API\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed an end-to-end ML deployment pipeline.\n",
    "\n",
    "This lab covered:\n",
    "- ✓ Model training and serialization\n",
    "- ✓ REST API development\n",
    "- ✓ Testing and benchmarking\n",
    "- ✓ Containerization\n",
    "- ✓ Documentation\n",
    "\n",
    "You're now ready to deploy production ML systems!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
