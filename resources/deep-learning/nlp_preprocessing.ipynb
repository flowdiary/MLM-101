{"cells":[{"cell_type":"markdown","metadata":{"id":"wrDHJqWhKV8W"},"source":["# Introduction to NLP: Text Preprocessing\n","\n","This notebook demonstrates fundamental text preprocessing techniques in Natural Language Processing (NLP) using Python's NLTK library. We'll cover:\n","\n","- **Text Cleaning**: Removing unwanted characters and normalizing text\n","- **Tokenization**: Splitting text into individual words or tokens\n","- **Stemming**: Reducing words to their root form\n","- **Lemmatization**: Converting words to their dictionary form\n","\n","These techniques are essential for preparing text data for various NLP tasks such as sentiment analysis, text classification, and more."]},{"cell_type":"markdown","metadata":{"id":"OVtAiL0xKV8Y"},"source":["## Setup and Imports\n","\n","First, let's import the necessary libraries and download required NLTK data."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQQ21sxKKV8Y","executionInfo":{"status":"ok","timestamp":1746309780086,"user_tz":-60,"elapsed":153,"user":{"displayName":"Abdullahi Ahmad","userId":"03775884294431603545"}},"outputId":"32c4830a-8b92-4ae2-8541-bb07987eff5e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.corpus import wordnet\n","import re\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('averaged_perceptron_tagger_eng')"]},{"cell_type":"markdown","metadata":{"id":"2hkGVTm-KV8Z"},"source":["## Helper Function for POS Tagging\n","\n","We need a helper function to map NLTK's POS tags to WordNet's format for accurate lemmatization."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9OmBezxVKV8Z","executionInfo":{"status":"ok","timestamp":1746309653829,"user_tz":-60,"elapsed":7,"user":{"displayName":"Abdullahi Ahmad","userId":"03775884294431603545"}}},"outputs":[],"source":["def get_wordnet_pos(word):\n","    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\n","        'J': wordnet.ADJ,\n","        'N': wordnet.NOUN,\n","        'V': wordnet.VERB,\n","        'R': wordnet.ADV\n","    }\n","    return tag_dict.get(tag, wordnet.NOUN)"]},{"cell_type":"markdown","metadata":{"id":"2Osx49a3KV8a"},"source":["## Main Preprocessing Function\n","\n","This function combines all preprocessing steps: cleaning, tokenization, stemming, and lemmatization."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CxaMB6VzKV8a","executionInfo":{"status":"ok","timestamp":1746309684902,"user_tz":-60,"elapsed":13,"user":{"displayName":"Abdullahi Ahmad","userId":"03775884294431603545"}}},"outputs":[],"source":["def preprocess_text(text):\n","    \"\"\"Perform text preprocessing: cleaning, tokenization, stemming, and lemmatization\"\"\"\n","    # 1. Text Cleaning\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove special characters and numbers\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","    # 2. Tokenization\n","    tokens = word_tokenize(text)\n","\n","    # 3. Stemming\n","    stemmer = PorterStemmer()\n","    stemmed_words = [stemmer.stem(token) for token in tokens]\n","\n","    # 4. Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_words = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n","\n","    return {\n","        'original': text,\n","        'tokens': tokens,\n","        'stemmed': stemmed_words,\n","        'lemmatized': lemmatized_words\n","    }"]},{"cell_type":"markdown","metadata":{"id":"TCZlIOYCKV8b"},"source":["## Example Usage\n","\n","Let's test our preprocessing function with a sample text and display the results."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1VJQDGvGKV8b","executionInfo":{"status":"ok","timestamp":1746309843643,"user_tz":-60,"elapsed":46,"user":{"displayName":"Abdullahi Ahmad","userId":"03775884294431603545"}},"outputId":"f997a8fa-ba44-49ea-c023-bf27abdf458c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text: the cats are running and jumping in the gardens and the gardens is good \n","Tokens: ['the', 'cats', 'are', 'running', 'and', 'jumping', 'in', 'the', 'gardens', 'and', 'the', 'gardens', 'is', 'good']\n","Stemmed Words: ['the', 'cat', 'are', 'run', 'and', 'jump', 'in', 'the', 'garden', 'and', 'the', 'garden', 'is', 'good']\n","Lemmatized Words: ['the', 'cat', 'be', 'run', 'and', 'jumping', 'in', 'the', 'garden', 'and', 'the', 'garden', 'be', 'good']\n"]}],"source":["# Sample text\n","sample_text = \"The cats are running and jumping in the gardens and the gardens is good \"\n","\n","# Process the text\n","result = preprocess_text(sample_text)\n","\n","# Display results\n","print(\"Original Text:\", result['original'])\n","print(\"Tokens:\", result['tokens'])\n","print(\"Stemmed Words:\", result['stemmed'])\n","print(\"Lemmatized Words:\", result['lemmatized'])"]},{"cell_type":"markdown","metadata":{"id":"-TPISoqMKV8b"},"source":["## Explanation of Results\n","\n","- **Original Text**: The cleaned, lowercase version of the input text.\n","- **Tokens**: The text split into individual words.\n","- **Stemmed Words**: Words reduced to their root form (e.g., 'running' → 'run').\n","- **Lemmatized Words**: Words converted to their dictionary form with proper POS tagging (e.g., 'running' → 'run', 'cats' → 'cat').\n","\n","This preprocessing pipeline is a foundation for many NLP applications. You can extend it by adding stop word removal, n-grams, or other techniques depending on your specific use case."]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}